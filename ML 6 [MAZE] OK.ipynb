{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c93b43-bc1a-41fa-9cbc-f6a6ba6af94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Q-Table:\n",
      "[[[-0.66994717 -0.0434062  -0.72079098 -0.57431084]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [-0.20192651  0.08350814 -0.15459721  0.8       ]\n",
      "  [-0.100707   -0.1000955   0.19705742  1.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.2974059   0.062882   -0.66028685 -0.66828771]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.62        0.0611404  -0.24705398 -0.32423864]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.21033193 -0.60577805 -0.61746673  0.18098   ]\n",
      "  [-0.5036096  -0.58932906 -0.12019543  0.3122    ]\n",
      "  [ 0.458      -0.13006347 -0.05289352 -0.13212132]\n",
      "  [-0.19346697 -0.199       0.03773287 -0.13924527]\n",
      "  [-0.27800766 -0.13918221 -0.1285528  -0.1909    ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [-0.13001813 -0.13021056 -0.49297517 -0.19770223]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [-0.14029794 -0.1389564  -0.3625377  -0.19171   ]]\n",
      "\n",
      " [[-0.199      -0.199      -0.28453345 -0.13228077]\n",
      "  [-0.35371    -0.199      -0.13121569 -0.1317071 ]\n",
      "  [-0.13123049 -0.199      -0.12982185 -0.199     ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [-0.13913746 -0.199      -0.199      -0.28728019]]]\n",
      "Path taken by the agent: [(0, 0), (1, 0), (2, 0), (2, 1), (2, 2), (1, 2), (0, 2), (0, 3), (0, 4)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define the maze\n",
    "maze = [\n",
    "    [0, -1, 0, 0, 1],\n",
    "    [0, -1, 0, -1, -1],\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [-1, -1, 0, -1, 0],\n",
    "    [0, 0, 0, -1, 0]\n",
    "]\n",
    "\n",
    "start = (0, 0)  # Starting point\n",
    "goal = (0, 4)   # Goal point\n",
    "\n",
    "# Map actions to numbers (0, 1, 2, 3)\n",
    "# 0 = up, 1 = down, 2 = left, 3 = right\n",
    "action_dict = {\n",
    "    0: (-1, 0),  # up\n",
    "    1: (1, 0),   # down\n",
    "    2: (0, -1),  # left\n",
    "    3: (0, 1)    # right\n",
    "}\n",
    "\n",
    "# Initialize Q-table with zeros (maze dimensions x number of actions)\n",
    "q_table = np.zeros((len(maze), len(maze[0]), 4))\n",
    "\n",
    "alpha = 0.1     # Learning rate\n",
    "gamma = 0.9     # Discount factor\n",
    "epsilon = 0.1   # Exploration rate\n",
    "episodes = 1000 # Number of episodes\n",
    "\n",
    "def is_valid_position(position):\n",
    "    row, col = position\n",
    "    return 0 <= row < len(maze) and 0 <= col < len(maze[0]) and maze[row][col] != -1\n",
    "\n",
    "def choose_action(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        # Random action (0, 1, 2, or 3)\n",
    "        return random.randint(0, 3)\n",
    "    else:\n",
    "        row, col = state\n",
    "        # Exploit the best action (max Q-value)\n",
    "        return np.argmax(q_table[row, col])  # Exploit the best action based on Q-table\n",
    "\n",
    "# Q-learning\n",
    "for episode in range(episodes):\n",
    "    state = start\n",
    "    while state != goal:\n",
    "        row, col = state\n",
    "        action = choose_action(state)\n",
    "\n",
    "        # Ensure valid action is chosen (safety check)\n",
    "        if action not in action_dict:\n",
    "            print(f\"Invalid action: {action}, using 0 (up) instead.\")\n",
    "            action = 0  # Default to 0 (up) in case of invalid action.\n",
    "\n",
    "        move = action_dict[action]\n",
    "        next_state = (row + move[0], col + move[1])\n",
    "\n",
    "        if not is_valid_position(next_state):\n",
    "            reward = -1  # Penalty for hitting a wall\n",
    "            next_state = state  # Stay in the same position\n",
    "        elif next_state == goal:\n",
    "            reward = 1  # Reward for reaching the goal\n",
    "        else:\n",
    "            reward = -0.1  # Small penalty for each move\n",
    "\n",
    "        # Update Q-value\n",
    "        next_row, next_col = next_state\n",
    "        best_next_action = np.max(q_table[next_row, next_col])\n",
    "        q_table[row, col, action] += alpha * (reward + gamma * best_next_action - q_table[row, col, action])\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "    # Decrease exploration rate over time\n",
    "    epsilon = max(0.01, epsilon * 0.99)\n",
    "\n",
    "# Print the trained Q-table\n",
    "print(\"Trained Q-Table:\")\n",
    "print(q_table)\n",
    "\n",
    "# Find the path using the trained Q-table\n",
    "state = start\n",
    "path = [state]\n",
    "while state != goal:\n",
    "    row, col = state\n",
    "    action = np.argmax(q_table[row, col])  # Choose the best action based on Q-values\n",
    "    move = action_dict[action]\n",
    "    next_state = (row + move[0], col + move[1])\n",
    "    if not is_valid_position(next_state):\n",
    "        break\n",
    "    state = next_state\n",
    "    path.append(state)\n",
    "\n",
    "# Print the path taken by the agent\n",
    "print(\"Path taken by the agent:\",path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818600b8-c293-4322-931d-2339cfdd5b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
